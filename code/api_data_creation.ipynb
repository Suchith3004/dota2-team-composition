{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac555c1-1988-429e-82f0-211e5252e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from sklearn import preprocessing, impute\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcc90af-4613-44cd-bf16-dec122632475",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://api.opendota.com/api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113bf9a3-6e74-4776-8f1c-1f9f1d8075ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limit = {'count' : 0,\n",
    "            'curr_time' : time.time(),\n",
    "             'total_cnt': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ff2f84-c25f-4c38-9092-069a0e4d7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(url_extensiton, rate_limit, params={}):\n",
    "    #Ensure rate limit of 60 calls/min is not exceeded\n",
    "    if rate_limit['count'] == 60:\n",
    "        rate_limit['count'] = 0\n",
    "        time_elapsed = time.time() - rate_limit['curr_time']\n",
    "        if time_elapsed < 60:\n",
    "            time.sleep(62 - time_elapsed)\n",
    "        rate_limit['curr_time'] = time.time()\n",
    "    \n",
    "    rate_limit['count'] += 1   \n",
    "    rate_limit['total_cnt'] += 1\n",
    "    if rate_limit['total_cnt'] == 50000:\n",
    "        print('monthly limit reached')\n",
    "    \n",
    "    # make get request\n",
    "    response = requests.get(api_url + url_extensiton, params=params)\n",
    "    if response.status_code != 200:\n",
    "        # if response.status_code == 429:\n",
    "        #     print(response.text)\n",
    "        return {'response_code': response.status_code,\n",
    "               'error': response.text}\n",
    "    else:\n",
    "        json_response = json.loads(response.text)\n",
    "        return {'response_code': 200,\n",
    "                'body': json_response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71cb08c0-ebb6-42e8-b640-c3ed030022c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve all hero names\n",
    "heroes_json = get_request('/heroes', rate_limit)\n",
    "\n",
    "heroes = dict()\n",
    "for hero in heroes_json['body']:\n",
    "    heroes[hero['id']] = hero['localized_name']\n",
    "    \n",
    "len(heroes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435644b-89b6-49b5-8023-afc9300ac22a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Large Instances and Small dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a191e32-9a31-4f79-85af-55774f5c3432",
   "metadata": {},
   "source": [
    "### Build the dataset with API SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e1c3c-6079-412b-a7f7-7bac7de7f6e6",
   "metadata": {},
   "source": [
    "#### Create single SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d347eb73-8d3e-4c1d-a9ba-9a6008f2b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that makes the full SQL query to the DOTA2 API\n",
    "def sql_query(match_id=None):\n",
    "    \n",
    "    # Define full query\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "\n",
    "    matches.match_id,\n",
    "    matches.radiant_team_id,\n",
    "    matches.dire_team_id,\n",
    "    matches.game_mode,\n",
    "    matches.cluster,\n",
    "    matches.lobby_type,\n",
    "    matches.radiant_win,\n",
    "    dire_team.her_o_ids as dire_heros,\n",
    "    radiant_team.her_o_ids as radiant_heros,\n",
    "    leagues.tier,\n",
    "    tr1.rating as dire_rating,\n",
    "    tr1.wins as dire_wins,\n",
    "    tr1.losses as dire_losses,\n",
    "    tr2.rating as radiant_rating,\n",
    "    tr2.wins as radiant_wins,\n",
    "    tr2.losses as radiant_losses\n",
    "    FROM matches\n",
    "    JOIN (SELECT match_id, string_agg(pl.hero_id::text, ',') as her_o_ids FROM player_matches as pl where player_slot < 5 group by match_id) as dire_team using (match_id)\n",
    "    JOIN (SELECT match_id, string_agg(pl.hero_id::text, ',') as her_o_ids FROM player_matches as pl where player_slot > 5 group by match_id) as radiant_team using (match_id)\n",
    "    JOIN leagues using(leagueid)\n",
    "    JOIN team_rating as tr1 ON tr1.team_id = matches.dire_team_id\n",
    "    JOIN team_rating as tr2 ON tr2.team_id = matches.radiant_team_id\n",
    "    WHERE matches.human_players = 10\n",
    "    AND matches.radiant_team_id IS NOT NULL\n",
    "    AND matches.dire_team_id IS NOT NULL\n",
    "    %s\n",
    "    ORDER BY matches.match_id DESC\n",
    "    LIMIT 20000;\n",
    "    \"\"\" % (\"AND matches.match_id < {}\".format(match_id) if match_id else \"\")\n",
    "\n",
    "    # Request data matching query\n",
    "    response = get_request('/explorer', rate_limit, {'sql':query})\n",
    "\n",
    "    #ensure error is not returned\n",
    "    if response['response_code'] == 200:\n",
    "        df = pd.DataFrame(response['body']['rows'])\n",
    "    else:\n",
    "        df = None\n",
    "        print(\"{} {}\".format(response['response_code'], response['error']))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacb39b-5161-4f38-b25b-8c594da5f398",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fetch all possible matches that fits the query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a7954-b0ed-4b5d-a7df-2411cc137c05",
   "metadata": {},
   "source": [
    "THIS CODE MAY NEED TO BE RUN A COUPLE TIMES FOR IT TO WORK. (API is glitchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d8fa4cf-b043-4384-80f4-0d9bde07b7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 16)\n",
      "5627655668\n",
      "(20000, 16)\n",
      "5068880258\n",
      "(20000, 16)\n",
      "3604296148\n",
      "(20000, 16)\n",
      "1943364461\n",
      "(20000, 16)\n",
      "357589264\n",
      "(4945, 16)\n",
      "19150047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104945, 16)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All instances cannot be retrieved at once, so it is done in batches of 20k\n",
    "\n",
    "# storage df\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Last ID that's retrieved\n",
    "min_id = None\n",
    "\n",
    "# Keep fetching until the maximum available matches have been found\n",
    "while True:\n",
    "    # Get a batch of matches\n",
    "    query_df = sql_query(min_id)\n",
    "    print(query_df.shape)\n",
    "    \n",
    "    #store the min match_id so next batch can be retrieve\n",
    "    min_id = min(query_df['match_id'])\n",
    "    print(min_id)\n",
    "    \n",
    "    # add batch to storage\n",
    "    df = pd.concat([df, query_df], ignore_index=False)\n",
    "    \n",
    "    if df.shape[0] > 103000: #manually found the max number of matches avialable\n",
    "        break\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83e384ae-d4bc-465d-a6b7-9ac8697b2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch dire and radiant data to double the dataset\n",
    "df_inv = df.copy()\n",
    "df_inv['radiant_win'] = ~df_inv['radiant_win']\n",
    "    \n",
    "# Flip all columns with dire and radiant directly in them\n",
    "flip = ['heros', 'rating', 'wins', 'losses']\n",
    "dire_flip = ['dire_' + i for i in flip]\n",
    "radiant_flip = ['radiant_' + i for i in flip]\n",
    "\n",
    "df_inv[radiant_flip] = df[dire_flip]\n",
    "df_inv[dire_flip] = df[radiant_flip]\n",
    "\n",
    "# add the duplicated instances to the original df\n",
    "df = pd.concat([df, df_inv], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b5004-375f-45b2-afd1-ce5c3b493583",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b31c4f89-f9b9-4428-a08a-8622b8f7f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one hot encoding to clusters and game_mode, as they are arbritary numbers relating to region\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['tier'] = le.fit_transform(df['tier'])\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "for column in ['cluster', 'game_mode', 'tier']:\n",
    "    encoded = enc.fit_transform(np.array(df[column]).reshape(-1,1))\n",
    "    encoded_names = [column + '_' + str(i) for i in range(len(encoded.toarray()[0]))]\n",
    "    df.loc[:, encoded_names] = encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d437fb7-04fe-4c81-a1af-a90cd5b3d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf272a-b906-4c96-984a-2f656fd26178",
   "metadata": {},
   "source": [
    "#### Create dataset with one-hot encoding on heroes (dire and radiant separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "670f412d-f22b-4537-a3d1-547edf18b88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suchi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "# Add one-hot encoding to heros, such that 121 heroes for both dire and radiant\n",
    "names = ['dire_{}'.format(str(i)) for i in heroes.values()]\n",
    "df[names] = [[1 if str(i) in j.split(',') else 0 for i in heroes.keys()] for j in df['dire_heros']]\n",
    "\n",
    "names = ['radiant_{}'.format(str(i)) for i in heroes.values()]\n",
    "df[names] = [[1 if str(i) in j.split(',') else 0 for i in heroes.keys()] for j in df['radiant_heros']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e4f1302-269d-458d-9692-eac18bd12931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the relevant columns\n",
    "skip = ['match_id', 'radiant_team_id', 'dire_team_id', 'dire_heros', 'radiant_heros', 'cluster', 'game_mode', 'tier']\n",
    "columns = [i for i in df.columns if i not in skip]\n",
    "df[columns].to_csv(\"../data/dota2_matches_large_encoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "69afbcc2-ce20-4fd5-95e4-0e0ef1ca80ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209890, 326)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82005be-642e-47cc-84f2-9c747cb4697f",
   "metadata": {},
   "source": [
    "#### Create dataset without encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7cb58e1d-2b0f-43e3-bb42-a4ea4166d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39e2908b-5b9b-4d9e-aa59-0831f37054b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine whether hero is chosen by a player in either team\n",
    "def hero_exists(hero, dires, radiants):\n",
    "    if hero in dires:\n",
    "        return 1\n",
    "    elif hero in radiants:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91a395b7-64e2-41c0-9624-d07c95580ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all hero choice columns\n",
    "df[list(heroes.values())] = [[hero_exists(str(i), d, r) for i in heroes.keys()] for d, r in zip(df['dire_heros'], df['radiant_heros'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a59a0821-f3ff-4ea4-8036-242d8a6fd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the relevant features\n",
    "skip = ['match_id', 'radiant_team_id', 'dire_team_id', 'dire_heros', 'radiant_heros', 'cluster', 'game_mode', 'tier']\n",
    "columns = [i for i in df.columns if i not in skip]\n",
    "df[columns].to_csv(\"../data/dota2_matches_large.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61e51bf1-1629-46be-9975-fe84649cc91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209890, 204)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[columns].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab9f22-d399-4bda-9554-7ed63b904624",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Small Instances and Large Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9865768-a0ba-4233-ad9a-2c2c0e4a3b24",
   "metadata": {},
   "source": [
    "WARNING: This section takes an 1-2 Hours to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ebeb2b-f66a-4a5e-bf8b-d65f57cb6274",
   "metadata": {},
   "source": [
    "### Build dataset from API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80852258-a7b0-4205-8c39-51481c884837",
   "metadata": {},
   "source": [
    "##### Retrieve pro matches, that have complete teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d508a1-2000-47ca-9023-eb47257e3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET 100 public matches\n",
    "matchIds = set()\n",
    "min_id = float('inf')\n",
    "while len(matchIds) < 500:\n",
    "    params = {} if min_id == float('inf') else {'less_than_match_id':min_id}        #Ensure same matches arent returned\n",
    "    pro_matches_json = get_request('/proMatches', rate_limit, params)               #100 pro matches\n",
    "    matchIds.update([match['match_id'] for match in pro_matches_json['body']])\n",
    "    min_id = min(min_id, min(matchIds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90c23b-cba9-45a8-a71d-a34f2b10be68",
   "metadata": {},
   "source": [
    "##### Retrieve match information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec519800-8d38-469b-98fc-c5a365aad793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve full match information for all proMatches\n",
    "matches = list()\n",
    "# for match in matchIds:\n",
    "while matchIds:\n",
    "    match = matchIds.pop()\n",
    "    match_json = get_request('/matches/' + str(match), rate_limit)\n",
    "    \n",
    "    # Ensure match IDs are actually returned\n",
    "    if match_json['response_code'] == 429:\n",
    "        matchIds.add(match)\n",
    "        continue    \n",
    "    elif match_json['response_code'] != 200:\n",
    "        print('{} --> {}'.format(match, match_json['response_code']))\n",
    "        continue\n",
    "        \n",
    "    matches.append(match_json['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b3927a-8346-43be-878f-37b30f39f2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7720ef3-cc01-4583-9e50-52dafb0bc09f",
   "metadata": {},
   "source": [
    "##### Retrieve player information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd196c-f043-4679-a076-e9b9b8c2656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of player IDs to go through\n",
    "player_ids = set()\n",
    "for match in matches:\n",
    "    accountIds = [player['account_id'] for player in match['players']]\n",
    "    player_ids.update(accountIds)\n",
    "len(player_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6ea2c-a557-42af-ac5c-2916a3bd2974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve individual player information\n",
    "count = 0\n",
    "players = dict()\n",
    "while player_ids:\n",
    "    # current player\n",
    "    accountId = player_ids.pop()\n",
    "    players[accountId] = dict()\n",
    "    \n",
    "    # Retrieve ranking information for player\n",
    "    playerInfo = get_request('/players/' + str(accountId), rate_limit)\n",
    "    rank_attr = ['solo_competitive_rank', 'leaderboard_rank', 'rank_tier', 'competitive_rank']\n",
    "    \n",
    "    # Format and store player statistics appropriately \n",
    "    if playerInfo['response_code'] == 200:\n",
    "        playerInfo = playerInfo['body']            \n",
    "        for attr in rank_attr:                \n",
    "             players[accountId][attr] = playerInfo[attr] if attr in playerInfo else np.NaN   \n",
    "        players[accountId]['mmr_estimate'] = playerInfo['mmr_estimate']['estimate'] if ('mmr_estimate' in playerInfo and 'estimate' in playerInfo['mmr_estimate']) else np.NaN\n",
    "    elif playerInfo['response_code'] == 429:\n",
    "        player_ids.add(accountId)\n",
    "        continue\n",
    "    else:\n",
    "        for attr in rank_attr:\n",
    "            players[accountId][attr] = np.NaN\n",
    "        players[accountId]['mmr_estimate'] = np.NaN\n",
    "\n",
    "        \n",
    "    # Retrieve win/lose ratio\n",
    "    playerInfo = get_request('/players/' + str(accountId) + '/wl', rate_limit)\n",
    "    if playerInfo['response_code'] == 200:\n",
    "        playerInfo = playerInfo['body']\n",
    "        players[accountId]['wl_ratio'] = playerInfo['win']/(playerInfo['win'] + playerInfo['lose'])\n",
    "    elif playerInfo['response_code'] == 429:\n",
    "        player_ids.add(accountId)\n",
    "        continue\n",
    "    else:\n",
    "        players[accountId]['wl_ratio'] = None\n",
    "            \n",
    "    # Retrieve win/lose ratio for hero\n",
    "    playerInfo = get_request('/players/' + str(accountId) + '/heroes', rate_limit)\n",
    "    players[accountId]['wl_hero_ratio'] = dict()\n",
    "    if playerInfo['response_code'] == 200:\n",
    "        playerInfo = playerInfo['body']\n",
    "        for hero in playerInfo:\n",
    "            win_ratio = 0 if hero['games'] == 0 else hero['win']/hero['games']\n",
    "            players[accountId]['wl_hero_ratio'][hero['hero_id']] = win_ratio\n",
    "    elif playerInfo['response_code'] == 429:\n",
    "        player_ids.add(accountId)\n",
    "        continue\n",
    "    else:\n",
    "        for hero in heroes.keys():\n",
    "               players[accountId]['wl_hero_ratio'][str(hero)] = 0\n",
    "    \n",
    "    # Retrieve average kill death rates for the previous matches\n",
    "    playerMatches = get_request('/players/' + str(accountId) + '/matches', rate_limit)\n",
    "    kda = ['kills', 'deaths', 'assists']\n",
    "    if playerMatches['response_code'] == 200:\n",
    "        playerMatches = playerMatches['body']\n",
    "        for attr in kda:\n",
    "            players[accountId]['avg_' + attr] = np.mean([mat[attr] for mat in playerMatches])\n",
    "    elif playerInfo['response_code'] == 429:\n",
    "        player_ids.add(accountId)\n",
    "        continue\n",
    "    else:\n",
    "        for attr in kda:\n",
    "            players[accountId]['avg_' + attr] = None\n",
    "    \n",
    "    # # Retrieve behavioral score and percent rank\n",
    "    # response = requests.get(api_url + '/players/' + str(accountId) + 'rankings')\n",
    "    # playerInfo = json.loads(response.text)\n",
    "    # players[accountId]['behavior_score'] = playerInfo['score']\n",
    "    # players[accountId]['percent_rank'] = playerInfo['percent_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21eb1c8-d560-4e38-a647-ca3f159f6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c85349-6434-4800-aac0-39cdfd4cc2b0",
   "metadata": {},
   "source": [
    "#### Store values in a formatted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e0fc5-393b-4e48-beeb-d9a0d5d563b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inverts hero choices by dire and radiant team\n",
    "def player_team(player):\n",
    "    if player['isRadiant']:\n",
    "        return 2\n",
    "    elif not player['isRadiant']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ecb8d-f822-4d27-a0f0-e26a9339ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine list of columns to average per team and attributes just related to the match\n",
    "columns = ['match_id', 'game_mode', 'cluster', 'league_tier' ]\n",
    "team_stats_names = ['solo_competitive_rank', 'leaderboard_rank', 'mmr_estimate', 'rank_tier', 'competitive_rank', 'wl_ratio', 'wl_hero_ratio', 'avg_kills', 'avg_deaths', 'avg_assists']\n",
    "columns.extend(heroes.values())\n",
    "\n",
    "data = pd.DataFrame(dict(), columns=columns)\n",
    "for match in matches:\n",
    "    # add basic match info to new rows\n",
    "    new_row = {'match_id': match['match_id'],\n",
    "               'game_mode': match['game_mode'], \n",
    "               'cluster': match['cluster'], \n",
    "               'human_players': match['human_players'],\n",
    "              'league_tier': match['league']['tier'] if ('league' in match and 'tier' in match['league']) else 'public'}\n",
    "        \n",
    "    #add heroes chosen by each team\n",
    "    for player in match['players']:\n",
    "        hero_name = heroes[player['hero_id']]\n",
    "        new_row[hero_name] = player_team(player)\n",
    "    \n",
    "    # add player information to new row\n",
    "    teams = dict()\n",
    "    teams['dire'] = [player['account_id'] for player in match['players'] if not player['isRadiant']]\n",
    "    teams['radiant'] = [player['account_id'] for player in match['players'] if player['isRadiant']]      \n",
    "        \n",
    "    # calculate distribute of player statistics per team\n",
    "    for attr in team_stats_names:\n",
    "        for team, team_ids in teams.items():\n",
    "            team_stats = list()\n",
    "            if attr == 'wl_hero_ratio':\n",
    "                for player in match['players']:\n",
    "                    accId = player['account_id']\n",
    "                    if accId in team_ids:\n",
    "                        hero_id = player['hero_id']\n",
    "                        if str(hero_id) in players[accId][attr]:\n",
    "                            team_stats.append(players[accId][attr][str(hero_id)])\n",
    "                        else:\n",
    "                            team_stats.append(players[accId][attr][heroes[hero_id]])\n",
    "            else:\n",
    "                team_stats = [players[i][attr] for i in team_ids]\n",
    "                \n",
    "            name = attr + '_' + team\n",
    "            \n",
    "            # Handle n/a cases\n",
    "            team_stats = [i for i in team_stats if i != None]\n",
    "            \n",
    "            # add player statistics \n",
    "            skip = ['leaderboard_rank', 'rank_tier']\n",
    "            if attr not in skip:\n",
    "                new_row['max_' + name] = max(team_stats) if team_stats else np.NaN\n",
    "                new_row['min_' + name] = min(team_stats) if team_stats else np.NaN\n",
    "                new_row['avg_' + name] = np.mean(team_stats) if team_stats else np.NaN\n",
    "                new_row['std_' + name] = np.std(team_stats) if team_stats else np.NaN    \n",
    "    \n",
    "    #add target \n",
    "    new_row['radiant_win'] = match['radiant_win']\n",
    "        \n",
    "    data = data.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e3215-a90d-4b55-8830-7cfa9f201437",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed10a7b-5c35-4264-beaf-521750220e99",
   "metadata": {},
   "source": [
    "#### Impute the missing data, as some players have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d8d71-3c54-4982-afb9-baf0b4c1b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the n/a values as 0 for hero choices\n",
    "data.loc[:, heroes.values()] = data[heroes.values()].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29549f10-cb07-4f8c-9de9-e0a8cfc974e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with large amounts of missing values (>=7)\n",
    "to_remove = [data.index[row] for row in range(data.shape[0]) if data.iloc[row].isnull().sum() >= 8]\n",
    "data.drop(to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a0855-30bd-4537-9a1c-d0306b1c9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply one hot encoding to clusters and game_mode, as they are arbritary numbers relating to region\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "encoded = enc.fit_transform(data[['cluster', 'game_mode', 'league_tier']])\n",
    "encoded_names = ['cluster_mode_league' + str(i) for i in range(len(encoded.toarray()[0]))]\n",
    "data.loc[:, encoded_names] = encoded.toarray()\n",
    "data.drop(['game_mode', 'cluster', 'league_tier'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7282ce-f68f-414c-a9eb-3a53d53f61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with mean\n",
    "imputer = impute.SimpleImputer()\n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0738a-a0d4-435b-b564-197dc2d9686d",
   "metadata": {},
   "source": [
    "#### Double instances by reversing existing instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089cb8c-ebbf-4f9b-8df6-4074f4e889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61ae627e-be0a-455c-8d5b-3510833c067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to invert team choice\n",
    "def hero_selection(team):\n",
    "    if team == 1:\n",
    "        return 2\n",
    "    elif team == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ea38e70-91a2-475b-a111-b07df5367cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844, 216)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create inverse sets\n",
    "df_inv = df.copy()\n",
    "df_inv['radiant_win'] = [not i for i in df['radiant_win']]\n",
    "    \n",
    "# Flip all the radiant and dire teams\n",
    "flip = ['solo_competitive_rank', 'leaderboard_rank', 'mmr_estimate', 'rank_tier', 'competitive_rank', 'wl_ratio', 'wl_hero_ratio', 'avg_kills', 'avg_deaths', 'avg_assists']\n",
    "flip = [i for i in df.columns if i.replace('_dire','').replace('_radiant','') in flip]\n",
    "dire_flip = [i for i in flip if 'dire' in i]\n",
    "radiant_flip = [i for i in flip if 'radiant' in i]\n",
    "\n",
    "df_inv[radiant_flip] = df[dire_flip]\n",
    "df_inv[dire_flip] = df[radiant_flip]\n",
    "\n",
    "#Flip heroes\n",
    "for col in heroes.values():\n",
    "    if col in df.columns:\n",
    "        df_inv[col] = [hero_selection(i) for i in df[col]]\n",
    "\n",
    "df = pd.concat([df, df_inv], ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afc65864-561c-4089-b0f2-6ac62869f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "df.drop([\"match_id\", \"human_players\"], axis=1, inplace=True)\n",
    "df.to_csv('../data/dota2_matches_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859782b0-c295-4631-bf3a-b736ac0a7a36",
   "metadata": {},
   "source": [
    "### Create an alternative dataset with one-hot encoding of heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2893c-480a-40cb-92e9-655444870039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b35363-99a5-4b41-9d38-bc5681c98d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode all the heroes columns\n",
    "for hero in heroes.values():\n",
    "    if hero in df.columns:\n",
    "        df['dire_' + hero] = [1 if i==1 else 0 for i in df[hero]]\n",
    "        df['radiant_' + hero] = [1 if i==2 else 0 for i in df[hero]]\n",
    "        df.drop(columns=hero, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffbf67e5-3b7f-4205-bf41-fede1bb5417c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844, 216)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create inverse sets\n",
    "df_inv = df.copy()\n",
    "df_inv['radiant_win'] = [not i for i in df['radiant_win']] # flip target class\n",
    "    \n",
    "# flip all the features for dire and radiant\n",
    "flip = ['solo_competitive_rank', 'leaderboard_rank', 'mmr_estimate', 'rank_tier', 'competitive_rank', 'wl_ratio', 'wl_hero_ratio', 'avg_kills', 'avg_deaths', 'avg_assists']\n",
    "flip = [i for i in df.columns if i.replace('_dire','').replace('_radiant','') in flip]\n",
    "dire_flip = [i for i in flip if 'dire' in i]\n",
    "radiant_flip = [i for i in flip if 'radiant' in i]\n",
    "\n",
    "df_inv[radiant_flip] = df[dire_flip]\n",
    "df_inv[dire_flip] = df[radiant_flip]\n",
    "\n",
    "df = pd.concat([df, df_inv], ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541255a6-20a4-4fa4-b797-12a5a2b786ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "df.drop([\"match_id\", \"human_players\"], axis=1, inplace=True)\n",
    "df.to_csv('../data/dota2_matches_small_encoded.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
